import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, f1_score
import matplotlib.pyplot as plt
from sklearn.inspection import permutation_importance
from collections import Counter
import sqlalchemy

# MySQL database configuration
db_config = {
    'username': 'root',
    'password': 'b5CaQ9WK2',
    'host': '127.0.0.1',
    'port': 3306,
    'database': 'chess'
}

# Create a SQLAlchemy engine
connection_url = (
    f"mysql+pymysql://{db_config['username']}:{db_config['password']}@"
    f"{db_config['host']}:{db_config['port']}/{db_config['database']}"
)
engine = sqlalchemy.create_engine(connection_url)

from sqlalchemy import text

# Create a connection
with engine.connect() as connection:
    # Ensure query is passed as a text object
    query_text = text("""
    SELECT 
        opening AS opening_name, 
        whiteelo AS WhiteElo, 
        blackelo AS BlackElo, 
        event AS Event, 
        result AS Result, 
        endgame, 
        DAY(date) AS day, 
        MONTH(date) AS month, 
        YEAR(date) AS year 
    FROM games 
    WHERE endgame IS NOT NULL AND endgame != 'endgame not reached'
    """)

    # Retrieve data into a pandas dataframe
    df = pd.read_sql(query_text, connection)



# Label encode the 'endgame' column
le_endgame = LabelEncoder()
df['endgame'] = le_endgame.fit_transform(df['endgame'])

# Encode categorical columns
le_result = LabelEncoder()
df['Result'] = le_result.fit_transform(df['Result'])

le_event = LabelEncoder()
df['Event'] = le_event.fit_transform(df['Event'])

le_opening = LabelEncoder()
df['opening_name'] = le_opening.fit_transform(df['opening_name'])

# Scale numerical columns
scaler = StandardScaler()
df[['WhiteElo', 'BlackElo', 'day', 'month', 'year']] = scaler.fit_transform(df[['WhiteElo', 'BlackElo', 'day', 'month', 'year']])

# Split the data into features and labels
X = df.drop('endgame', axis=1)  # Features
y = df['endgame']  # Target variable

# Check the class distribution before balancing
print("Class distribution before balancing:", Counter(y))

# Remove classes with fewer than 2 samples
min_samples = 4
class_counts = y.value_counts()
valid_classes = class_counts[class_counts >= min_samples].index

# Filter the dataset to only include valid classes
X = X[y.isin(valid_classes)]
y = y[y.isin(valid_classes)]

# Check class distribution after filtering
print("Class distribution after filtering rare classes:", Counter(y))

# Use SMOTE to balance classes
smote = SMOTE(random_state=42, k_neighbors=3)
X_balanced, y_balanced = smote.fit_resample(X, y)

# Check class distribution after SMOTE
print("Class distribution after balancing:", Counter(y_balanced))

# Split the balanced dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)

# Train a K-Nearest Neighbors model
knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train, y_train)

# Make predictions
y_pred = knn_model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average='weighted')  # Weighted F1 score for imbalanced classes
print(f'KNN Classifier Accuracy: {accuracy:.2f}')
print(f'KNN F1 Score (Weighted): {f1:.2f}')



# Feature Importance using Permutation Importance
perm_importance = permutation_importance(knn_model, X_test, y_test, n_repeats=10, random_state=42)

# Get the feature importances and sort by importance
importances = perm_importance.importances_mean
indices = importances.argsort()  # Sort indices by feature importance

# Plot Feature Importance (same style as Random Forest model)
plt.figure(figsize=(16, 6))
plt.title('Feature Importances (Permutation Importance)')
plt.bar(range(len(indices)), importances[indices], align='center')
plt.xticks(range(len(indices)), [X.columns[i] for i in indices], rotation=90)
plt.xlabel('Features')
plt.ylabel('Importance')
plt.tight_layout()
plt.show()