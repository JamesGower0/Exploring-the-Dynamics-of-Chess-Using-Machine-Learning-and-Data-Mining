import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from keras.models import Sequential
from keras.layers import Dense, Dropout
from imblearn.over_sampling import SMOTE
from collections import Counter
import matplotlib.pyplot as plt
from keras.optimizers import Adam
from sklearn.metrics import f1_score
import sqlalchemy
import pymysql

# Check GPU availability
print("Num GPUs Available:", len(tf.config.list_physical_devices('GPU')))

gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print("GPU memory growth enabled")
    except RuntimeError as e:
        print(e)

# Enable mixed precision training
from tensorflow.keras.mixed_precision import set_global_policy
set_global_policy('mixed_float16')

# Training Parameters
EPOCHS = 128
BATCH_SIZE = 128
ACTIVATION = 'relu'

# MySQL database configuration
db_config = {
    'username': 'root',
    'password': 'b5CaQ9WK2',
    'host': '127.0.0.1',
    'port': 3306,
    'database': 'chess'
}

# Create a SQLAlchemy engine
connection_url = (
    f"mysql+pymysql://{db_config['username']}:{db_config['password']}@"
    f"{db_config['host']}:{db_config['port']}/{db_config['database']}"
)
engine = sqlalchemy.create_engine(connection_url)

# Query to get the chess opening data
query = """
SELECT 
    opening AS opening_name, 
    whiteelo AS WhiteElo, 
    blackelo AS BlackElo, 
    event AS Event, 
    result AS Result, 
    endgame, 
    DAY(date) AS day, 
    MONTH(date) AS month, 
    YEAR(date) AS year 
FROM games 
WHERE endgame IS NOT NULL AND endgame != 'endgame not reached'
"""

df = pd.read_sql(query, engine)
print(df.head())

# Label Encoding
le_endgame = LabelEncoder()
df['endgame'] = le_endgame.fit_transform(df['endgame'])
le_opening_name = LabelEncoder()
df['opening_name'] = le_opening_name.fit_transform(df['opening_name'])
le_result = LabelEncoder()
df['Result'] = le_result.fit_transform(df['Result'])
le_event = LabelEncoder()
df['Event'] = le_event.fit_transform(df['Event'])

# Scaling numerical columns
scaler = StandardScaler()
df[['WhiteElo', 'BlackElo', 'day', 'month', 'year']] = scaler.fit_transform(
    df[['WhiteElo', 'BlackElo', 'day', 'month', 'year']]
)

# Features and labels
X = df.drop('endgame', axis=1)
y = df['endgame']
print("Class distribution before balancing:", Counter(y))

# Remove rare classes
min_samples = 4
class_counts = y.value_counts()
valid_classes = class_counts[class_counts >= min_samples].index
X = X[y.isin(valid_classes)]
y = y[y.isin(valid_classes)]
print("Class distribution after filtering rare classes:", Counter(y))

# Apply SMOTE
smote = SMOTE(random_state=42, k_neighbors=3)
X_balanced, y_balanced = smote.fit_resample(X, y)
print("Class distribution after balancing:", Counter(y_balanced))

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)

# Create a neural network model
with tf.device('/GPU:0'):
    model = Sequential()
    model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))
    model.add(Dense(128, activation='relu'))
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.08))
    model.add(Dense(128, activation='relu'))
    model.add(Dense(128, activation='relu'))
    model.add(Dense(128, activation='relu'))
    model.add(Dense(len(le_endgame.classes_), activation='softmax')) 

# Compile with optimized Adam
optimizer = Adam(learning_rate=0.001, jit_compile=True)
model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)

# Train the model
history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_test, y_test))

# Evaluate
loss, accuracy = model.evaluate(X_test, y_test)
print(f'Accuracy: {accuracy:.2f}')

# Predictions
predictions = model.predict(X_test)
predicted_classes = predictions.argmax(axis=1)
f1 = f1_score(y_test, predicted_classes, average='weighted')
print(f'F1 Score (Weighted): {f1:.2f}')

# Decode predictions
predicted_endgames = le_endgame.inverse_transform(predicted_classes)
print(predicted_endgames[:1000])

# Plot results
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()
